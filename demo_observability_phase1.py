#!/usr/bin/env python3\n\"\"\"Comprehensive demo of Phase 1 Observability implementation.\"\"\"\n\nimport asyncio\nimport time\nimport sys\nimport os\nfrom pathlib import Path\n\n# Add the src directory to Python path\nsrc_path = Path(__file__).parent / \"src\"\nsys.path.insert(0, str(src_path))\n\nfrom observability import (\n    setup_logging, \n    get_logger, \n    RequestContext,\n    operation_context,\n    log_model_operation,\n    log_qdrant_operation,\n    log_file_processing,\n    LogConfig\n)\n\n\ndef demo_json_logging():\n    \"\"\"Demo JSON structured logging format.\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"üìä JSON STRUCTURED LOGGING DEMO\")\n    print(\"=\"*60)\n    \n    os.environ['LOG_FORMAT'] = 'json'\n    os.environ['LOG_LEVEL'] = 'INFO'\n    \n    config = LogConfig.from_env()\n    setup_logging(config.level, config.format, config.output)\n    \n    logger = get_logger('json_demo')\n    \n    # Basic structured log\n    logger.info(\"Server startup\", \n                version=\"2.0.0\", \n                port=50051, \n                cuda_available=True)\n    \n    # Request processing with context\n    with RequestContext(\n        \"req-001\", \n        method=\"GetEmbeddings\", \n        user_id=\"user123\",\n        model=\"BAAI/bge-large-en-v1.5\"\n    ):\n        logger.info(\"Processing batch request\", \n                   batch_size=25,\n                   estimated_tokens=1500)\n        \n        with operation_context(\"model_inference\", tokens=1500) as op:\n            time.sleep(0.05)  # Simulate processing\n            logger.info(\"Inference completed\", **op)\n            \n        # Model-specific operation\n        log_model_operation(\n            operation=\"embedding_generation\",\n            model_name=\"BAAI/bge-large-en-v1.5\",\n            duration=0.23,\n            batch_size=25,\n            tokens_processed=1500\n        )\n\n\ndef demo_text_logging():\n    \"\"\"Demo human-readable text logging format.\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"üìñ TEXT READABLE LOGGING DEMO\")\n    print(\"=\"*60)\n    \n    os.environ['LOG_FORMAT'] = 'text'\n    os.environ['LOG_LEVEL'] = 'DEBUG'\n    \n    config = LogConfig.from_env()\n    setup_logging(config.level, config.format, config.output)\n    \n    logger = get_logger('text_demo')\n    \n    # Debug and info logs\n    logger.debug(\"Loading model configuration\", \n                model=\"sentence-transformers/all-MiniLM-L6-v2\")\n    \n    with RequestContext(\"req-002\", method=\"ProcessFileStream\") as ctx:\n        logger.info(\"File upload received\", \n                   filename=\"document.pdf\",\n                   size_mb=2.5)\n        \n        logger.warning(\"Large file detected, chunking required\", \n                      chunk_size=512)\n        \n        with operation_context(\"text_chunking\", chunks_expected=45):\n            time.sleep(0.03)\n            logger.info(\"Chunking completed\")\n\n\ndef demo_error_handling():\n    \"\"\"Demo comprehensive error logging and tracing.\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"üö® ERROR HANDLING & TRACING DEMO\")\n    print(\"=\"*60)\n    \n    os.environ['LOG_FORMAT'] = 'json'\n    os.environ['LOG_LEVEL'] = 'ERROR'\n    \n    config = LogConfig.from_env()\n    setup_logging(config.level, config.format, config.output)\n    \n    logger = get_logger('error_demo')\n    \n    # Error scenarios with full context\n    with RequestContext(\"req-003\", method=\"LoadModel\", model=\"invalid/model\"):\n        try:\n            with operation_context(\"model_validation\") as op:\n                raise ValueError(\"Model 'invalid/model' not found in registry\")\n        except ValueError:\n            pass  # Context manager logs the error\n    \n    # Specialized error logging\n    log_model_operation(\n        operation=\"model_load\",\n        model_name=\"non-existent-model\",\n        error=\"HuggingFace model repository not found\",\n        attempted_path=\"/models/non-existent-model\",\n        timeout_seconds=30\n    )\n    \n    log_qdrant_operation(\n        operation=\"connection_test\",\n        collection=\"test\",\n        error=\"Connection refused: localhost:6333\",\n        retry_count=3,\n        duration=5.2\n    )\n\n\ndef demo_performance_tracking():\n    \"\"\"Demo performance metrics and timing.\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"‚ö° PERFORMANCE TRACKING DEMO\")\n    print(\"=\"*60)\n    \n    os.environ['LOG_FORMAT'] = 'json'\n    os.environ['LOG_LEVEL'] = 'INFO'\n    \n    config = LogConfig.from_env()\n    setup_logging(config.level, config.format, config.output)\n    \n    # Simulate a complete file processing workflow\n    with RequestContext(\"req-004\", method=\"ProcessFileStream\", \n                       user_id=\"perf_test\", model=\"BAAI/bge-large-en-v1.5\"):\n        \n        # Model loading timing\n        with operation_context(\"model_loading\", model=\"BAAI/bge-large-en-v1.5\") as op:\n            time.sleep(0.15)  # Simulate model load\n            log_model_operation(\n                operation=\"model_load\",\n                model_name=\"BAAI/bge-large-en-v1.5\",\n                duration=op.get('duration', 0.15),\n                memory_usage_mb=1024,\n                cuda_device=\"NVIDIA GeForce RTX 3090 Ti\"\n            )\n        \n        # Text processing pipeline\n        with operation_context(\"file_preprocessing\", size_mb=5.2) as op:\n            time.sleep(0.08)\n            \n        with operation_context(\"text_chunking\", chunk_size=512) as op:\n            time.sleep(0.12)\n            \n        with operation_context(\"embedding_generation\", batch_size=42) as op:\n            time.sleep(0.35)\n            \n        with operation_context(\"qdrant_storage\", collection=\"documents\") as op:\n            time.sleep(0.09)\n            log_qdrant_operation(\n                operation=\"upsert_points\",\n                collection=\"documents\",\n                points_count=42,\n                duration=op.get('duration', 0.09),\n                batch_size=42\n            )\n        \n        # Overall file processing summary\n        log_file_processing(\n            filename=\"large_document.pdf\",\n            size_bytes=5452595,  # ~5.2MB\n            chunks_count=42,\n            duration=0.79,  # Total processing time\n            model=\"BAAI/bge-large-en-v1.5\",\n            stored_to_qdrant=True\n        )\n\n\ndef demo_file_output():\n    \"\"\"Demo logging to file with rotation.\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"üìÑ FILE LOGGING DEMO\")\n    print(\"=\"*60)\n    \n    log_file = \"./logs/demo_output.log\"\n    \n    # Ensure logs directory exists\n    os.makedirs(\"./logs\", exist_ok=True)\n    \n    setup_logging(\n        level='INFO',\n        format_type='json', \n        output_type='file',\n        file_path=log_file,\n        max_size='1MB',\n        backup_count=3\n    )\n    \n    logger = get_logger('file_demo')\n    \n    logger.info(\"File logging test started\", \n               log_file=log_file,\n               rotation_enabled=True)\n    \n    # Generate some log entries\n    for i in range(10):\n        with RequestContext(f\"batch-{i:03d}\", method=\"GetEmbeddings\"):\n            logger.info(f\"Processing batch {i+1}/10\", \n                       batch_id=i+1,\n                       items_count=(i+1)*5)\n            time.sleep(0.01)\n    \n    logger.info(\"File logging test completed\")\n    \n    # Show file contents\n    if os.path.exists(log_file):\n        print(f\"\\nüìÑ Contents of {log_file}:\")\n        print(\"-\" * 40)\n        with open(log_file, 'r') as f:\n            lines = f.readlines()\n            for line in lines[:5]:  # Show first 5 lines\n                print(line.strip())\n            if len(lines) > 5:\n                print(f\"... and {len(lines) - 5} more lines\")\n    \n\ndef demo_configuration_management():\n    \"\"\"Demo environment-based configuration.\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"‚öôÔ∏è  CONFIGURATION MANAGEMENT DEMO\")\n    print(\"=\"*60)\n    \n    # Show different configuration scenarios\n    scenarios = [\n        {\n            \"name\": \"Development\",\n            \"env\": {\n                \"LOG_LEVEL\": \"DEBUG\",\n                \"LOG_FORMAT\": \"text\",\n                \"LOG_OUTPUT\": \"console\"\n            }\n        },\n        {\n            \"name\": \"Production\", \n            \"env\": {\n                \"LOG_LEVEL\": \"WARNING\",\n                \"LOG_FORMAT\": \"json\",\n                \"LOG_OUTPUT\": \"file\",\n                \"LOG_FILE_PATH\": \"./logs/production.log\"\n            }\n        },\n        {\n            \"name\": \"Monitoring\",\n            \"env\": {\n                \"LOG_LEVEL\": \"INFO\",\n                \"LOG_FORMAT\": \"json\", \n                \"LOG_OUTPUT\": \"console\",\n                \"LOG_REMOTE_ENDPOINT\": \"http://logstash:5000\"\n            }\n        }\n    ]\n    \n    for scenario in scenarios:\n        print(f\"\\nüîß {scenario['name']} Configuration:\")\n        \n        # Set environment\n        for key, value in scenario['env'].items():\n            os.environ[key] = value\n        \n        # Load and validate config\n        config = LogConfig.from_env()\n        try:\n            config.validate()\n            print(f\"   ‚úì Level: {config.level}\")\n            print(f\"   ‚úì Format: {config.format}\")\n            print(f\"   ‚úì Output: {config.output}\")\n            if config.file_path != \"/app/logs/fastembed.log\":\n                print(f\"   ‚úì File: {config.file_path}\")\n            if config.remote_endpoint:\n                print(f\"   ‚úì Remote: {config.remote_endpoint}\")\n        except ValueError as e:\n            print(f\"   ‚úó Validation failed: {e}\")\n\n\ndef main():\n    \"\"\"Run the complete observability demo.\"\"\"\n    print(\"üöÄ FastEmbed Server Observability Phase 1 Demo\")\n    print(\"üìÖ Implementation Date: June 2025\")\n    print(\"üí° Features: Structured logging, Request tracing, Performance metrics\")\n    \n    try:\n        demo_configuration_management()\n        demo_json_logging()\n        demo_text_logging() \n        demo_performance_tracking()\n        demo_error_handling()\n        demo_file_output()\n        \n        print(\"\\n\" + \"=\"*60)\n        print(\"‚úÖ PHASE 1 OBSERVABILITY DEMO COMPLETED\")\n        print(\"=\"*60)\n        print(\"\\nüéØ Key Features Demonstrated:\")\n        print(\"   ‚Ä¢ Structured JSON & readable text logging\")\n        print(\"   ‚Ä¢ Request correlation & context tracking\") \n        print(\"   ‚Ä¢ Operation timing & performance metrics\")\n        print(\"   ‚Ä¢ Comprehensive error handling & tracing\")\n        print(\"   ‚Ä¢ Environment-based configuration\")\n        print(\"   ‚Ä¢ File output with rotation support\")\n        print(\"   ‚Ä¢ Specialized logging for models, Qdrant & files\")\n        \n        print(\"\\nüöÄ Ready for Phase 2: Prometheus Metrics!\")\n        print(\"   ‚Ä¢ Request counters & histograms\")\n        print(\"   ‚Ä¢ Business logic metrics\")\n        print(\"   ‚Ä¢ Resource utilization tracking\" )\n        print(\"   ‚Ä¢ gRPC/HTTP middleware integration\")\n        \n    except Exception as e:\n        print(f\"\\n‚ùå Demo failed: {e}\")\n        import traceback\n        traceback.print_exc()\n\n\nif __name__ == \"__main__\":\n    main()